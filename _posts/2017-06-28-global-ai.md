---
layout: post
title: My Experience At the 2017 Global AI Hackathon 2017
cover: colorful-1325268_1280.jpg
date:   2017-06-28 01:00:00 -0800
categories: posts
---

Several weeks ago, I was in the Science Museum in Hyde Park, London, in the
History of Mathematics exhibit. I was so overwhelmed by all of the great things that other people had done, that I felt somewhat ashamed of how little of an impact I have had on the world. I felt like I could be expanding my mind
so much more than I was allowing. I thought, I don't need to take more classes, and I don't need to have a certain degree. I just need to get out there and contribute.

At that moment, I had a mini-piphany, which is like an epiphany except that it
doesn't result in a spiritual awakening or a religious movement. No, this
mini-piphany resulted in a google search for upcoming hackathons. Why so
specific, you might ask? Well, it's quite simple. I know that I can only
accomplish so much alone, so I knew that I needed more exposure to brilliant
and ambitious people. Secondly, I knew that I needed to be pushed beyond my
limits in order to understand what it takes to contribute to new ideas. And
finally, I needed to get exposure to the latest technological breakthroughs
in my field, to make sure I'm not repeating things that have already been done.

And so, this past weekend I participated in my first hackathon, the Global AI Hackathon, at its NYC location. As far as I know, this was definitely not a traditional hackathon. it was very open-ended, and it was for people from all kinds of backgrounds to come together and make some kind of AI-based solution. I had no idea what to expect, but after having done it, I can say with confidence that if anyone is ever on the fence about doing a hackathon, they should go ahead and do one.

My team selected one of three challenges that requested a product that implements AI technology (hopefully from one of the sponsors) to provide a particular solution. In our case, we chose to develop a tool that attempts to tag news as "fake" or not. Yes, I know, it's kind of a fad right now, but it is a useful thing to have. Some models are already out there, such as the BS Detector, but they could all still use a little work. Our output ended up being [Austd]() (_Gold Standard_, abbreviated). It's a Twilio app where you can text an article URL and receive a guess as to whether it's safe with a confidence score. It also checks to see if the website is already labelled as biased or fake by [OpenSources](http://www.opensources.co/), an open soruce list of questionable news sources, and lets you know if it's already flagged.

The model implements Bing's spell checker to count number of typos, and it uses a [subjectivity lexicon](http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/) to score how subjective the language is as well as the negativity of the text body. It also measures neutrality of the title using VADER sentiment intensity analysis. All of these features were thrown into a Random Forest Classifier. The final model was selected because it fared better than Logistic and SVM models, but that still needs some research.

I was quite happy with the output. Below is a snapshot of how it worked:

![Austd in Action]({{ site.url }}{{ site.baseurl }}/images/ai_snapshot.jpg)

This project is still a work in progress. While we had something presentable at the end of the weekend, everyone on my team were newbies, and we freaked out and bailed out of the presentation, thinking everyone else was a genius. After looking at the winners online, though, I honestly think Austd could've gotten at the very least a bit more than a polite applause. At my next hackathon, I promise not to chicken out, but in the meantime, I had a blast and hope to go again next year.

View the github repo [here](https://github.com/stephperk/austd)!
